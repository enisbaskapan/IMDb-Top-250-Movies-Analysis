{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDb Top 250 Movies Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup  \n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = open('imdbtop250.csv', 'w', encoding='UTF8')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow(['rank', 'title', 'year', 'director', 'duration(minutes)', 'genre', 'rating', 'gross', 'oscars', 'awards', 'nominations'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/chart/top'\n",
    "response = requests.get(url)\n",
    "response.raise_for_status() #error   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get info from individual movie links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def more_info(url):\n",
    "    detail = requests.get(url)\n",
    "    soup = BeautifulSoup(detail.text, \"html.parser\")\n",
    "    style = soup.find('div', class_='sc-910a7330-4 kcpPzf')\n",
    "    if style:\n",
    "        gd = style\n",
    "    else:\n",
    "        gd = soup.find('div', class_='sc-fa02f843-0 fjLeDR')\n",
    "    \n",
    "    genres = []\n",
    "    oscars = []\n",
    "    \n",
    "    # Genre\n",
    "    if gd == style:\n",
    "        for genre in gd.find_all('span', class_='ipc-chip__text'): genres.append(genre.text)\n",
    "    else: \n",
    "        for genre in soup.find('div', class_='ipc-chip-list__scroller').find_all('span', class_='ipc-chip__text'): genres.append(genre.text)\n",
    "\n",
    "    # Gross\n",
    "    try:\n",
    "        gross_ = soup.find_all('ul', class_='ipc-metadata-list ipc-metadata-list--dividers-none ipc-metadata-list--compact sc-6d4f3f8c-0 ejRbxb ipc-metadata-list--base')[0].find_all('li', class_='ipc-inline-list__item')[-1].text.replace('$','').replace(',','')\n",
    "        gross = int(gross_)\n",
    "    except:\n",
    "        gross = None\n",
    "    # Director \n",
    "    director = gd.find('li', class_='ipc-inline-list__item').text\n",
    "    \n",
    "    # Runtime in minutes\n",
    "    runtime = soup.find('div', class_='sc-94726ce4-3 eSKKHi').ul.find_all('li', class_='ipc-inline-list__item')[2].text\n",
    "    time = re.findall('\\d+', runtime)\n",
    "    if len(time) > 1: minutes = int(time[0])*60 + int(time[1]) \n",
    "    else:\n",
    "        if len(time[0])<2: minutes = int(time[0])*60 \n",
    "        else: minutes = int(time[0])\n",
    "    \n",
    "    award = soup.find('div', class_='sc-fcdc3619-0 YgLMu base').ul.text\n",
    "    num = re.findall('\\d+', award)\n",
    "    if award.split(' ')[0] == 'Won': oscars.append(int(num[0][0]))\n",
    "    elif award.split(' ')[0] == 'Nominated': oscars.append(0)\n",
    "    else: oscars.append(0) # if there are no nominations \n",
    "   \n",
    "    return genres, director, minutes, gross, oscars[0], num[len(num)-2], num[len(num)-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main page scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = soup.find('tbody', class_='lister-list').find_all('tr')\n",
    "for movie in movies:\n",
    "    rank = movie.find('td', class_='titleColumn').get_text(strip=True).split('.')[0]\n",
    "    name = movie.find('td', class_='titleColumn').a.text\n",
    "    year = movie.find('td', class_='titleColumn').span.text.replace('(','').replace(')','')\n",
    "    rating = movie.find('td', class_='ratingColumn imdbRating').strong.text\n",
    "    \n",
    "    base = 'https://www.imdb.com/'\n",
    "    href = movie.find('td', class_='titleColumn').a.get('href')\n",
    "    url = base+href  \n",
    "    \n",
    "    genres, director, minutes, gross, oscars, awards, nominations = more_info(url)\n",
    "    \n",
    "    csv_writer.writerow([rank, name, year, director, minutes, genres, rating, gross, oscars, awards, nominations])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
